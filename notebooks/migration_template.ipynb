{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Google Drive Migration Helper\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì„ ì‚¬ìš©í•˜ì—¬ ê°œì¸ Google ê³„ì •ì—ì„œ íšŒì‚¬ Google ê³„ì •ìœ¼ë¡œ íŒŒì¼ì„ ë§ˆì´ê·¸ë ˆì´ì…˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "## ì‚¬ìš© ì „ ì¤€ë¹„ì‚¬í•­\n",
        "1. Google Cloud Consoleì—ì„œ OAuth 2.0 í´ë¼ì´ì–¸íŠ¸ ID ìƒì„±\n",
        "2. `credentials.json` íŒŒì¼ì„ ì´ ë…¸íŠ¸ë¶ê³¼ ê°™ì€ í´ë”ì— ì—…ë¡œë“œ\n",
        "3. ë§ˆì´ê·¸ë ˆì´ì…˜í•  íŒŒì¼ë“¤ì´ ê°œì¸ ê³„ì •ì— ìˆëŠ”ì§€ í™•ì¸\n",
        "\n",
        "## ì£¼ì˜ì‚¬í•­\n",
        "- ë§ˆì´ê·¸ë ˆì´ì…˜ì€ ë˜ëŒë¦´ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì‹ ì¤‘í•˜ê²Œ ì§„í–‰í•˜ì„¸ìš”\n",
        "- ëŒ€ìš©ëŸ‰ íŒŒì¼ì˜ ê²½ìš° ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
        "- ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì´ ì•ˆì •ì ì¸ í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸\n",
        "%pip install google-api-python-client google-auth-oauthlib google-auth-httplib2\n",
        "%pip install pandas tqdm python-dotenv\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.credentials import Credentials\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "\n",
        "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Drive API ì„¤ì •\n",
        "SCOPES = [\n",
        "    'https://www.googleapis.com/auth/drive',\n",
        "    'https://www.googleapis.com/auth/drive.file',\n",
        "    'https://www.googleapis.com/auth/drive.metadata',\n",
        "    'https://www.googleapis.com/auth/drive.readonly'\n",
        "]\n",
        "\n",
        "# íŒŒì¼ ì„¤ì •\n",
        "CREDENTIALS_FILE = 'credentials.json'\n",
        "PERSONAL_TOKEN_FILE = 'personal_token.json'\n",
        "WORK_TOKEN_FILE = 'work_token.json'\n",
        "\n",
        "# ë§ˆì´ê·¸ë ˆì´ì…˜ ì„¤ì •\n",
        "MAX_FILE_SIZE = 5 * 1024 * 1024 * 1024  # 5GB\n",
        "BATCH_SIZE = 100\n",
        "MAX_RETRIES = 3\n",
        "\n",
        "print(\"âœ… ì„¤ì • ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def authenticate_google_account(credentials_file, token_file, account_name):\n",
        "    \"\"\"\n",
        "    Google ê³„ì • ì¸ì¦\n",
        "    \n",
        "    Args:\n",
        "        credentials_file: ì¸ì¦ íŒŒì¼ ê²½ë¡œ\n",
        "        token_file: í† í° ì €ì¥ íŒŒì¼ ê²½ë¡œ\n",
        "        account_name: ê³„ì • ì´ë¦„ (í‘œì‹œìš©)\n",
        "    \n",
        "    Returns:\n",
        "        googleapiclient.discovery.Resource: Google Drive API ì„œë¹„ìŠ¤\n",
        "    \"\"\"\n",
        "    creds = None\n",
        "    \n",
        "    # ê¸°ì¡´ í† í° ë¡œë“œ\n",
        "    if os.path.exists(token_file):\n",
        "        creds = Credentials.from_authorized_user_file(token_file, SCOPES)\n",
        "    \n",
        "    # í† í°ì´ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°\n",
        "    if not creds or not creds.valid:\n",
        "        if creds and creds.expired and creds.refresh_token:\n",
        "            # í† í° ê°±ì‹ \n",
        "            creds.refresh(Request())\n",
        "        else:\n",
        "            # ìƒˆ ì¸ì¦ í”Œë¡œìš°\n",
        "            flow = InstalledAppFlow.from_client_secrets_file(credentials_file, SCOPES)\n",
        "            creds = flow.run_local_server(port=0)\n",
        "        \n",
        "        # í† í° ì €ì¥\n",
        "        with open(token_file, 'w') as token:\n",
        "            token.write(creds.to_json())\n",
        "    \n",
        "    # Google Drive API ì„œë¹„ìŠ¤ ìƒì„±\n",
        "    service = build('drive', 'v3', credentials=creds)\n",
        "    \n",
        "    # ì‚¬ìš©ì ì •ë³´ í™•ì¸\n",
        "    try:\n",
        "        about = service.about().get(fields='user').execute()\n",
        "        user_info = about.get('user', {})\n",
        "        print(f\"âœ… {account_name} ê³„ì • ì¸ì¦ ì™„ë£Œ: {user_info.get('displayName', 'Unknown')} ({user_info.get('emailAddress', 'Unknown')})\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ {account_name} ê³„ì • ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
        "    \n",
        "    return service\n",
        "\n",
        "print(\"âœ… ì¸ì¦ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê³„ì • ì¸ì¦ ì‹¤í–‰\n",
        "print(\"ğŸ” Google ê³„ì • ì¸ì¦ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# ê°œì¸ ê³„ì • ì¸ì¦\n",
        "print(\"1ï¸âƒ£ ê°œì¸ Google ê³„ì • ì¸ì¦\")\n",
        "personal_service = authenticate_google_account(CREDENTIALS_FILE, PERSONAL_TOKEN_FILE, \"ê°œì¸\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "\n",
        "# íšŒì‚¬ ê³„ì • ì¸ì¦  \n",
        "print(\"2ï¸âƒ£ íšŒì‚¬ Google ê³„ì • ì¸ì¦\")\n",
        "work_service = authenticate_google_account(CREDENTIALS_FILE, WORK_TOKEN_FILE, \"íšŒì‚¬\")\n",
        "\n",
        "print(\"\\nâœ… ëª¨ë“  ê³„ì • ì¸ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scan_drive_files(service, folder_id='root', folder_name='Root'):\n",
        "    \"\"\"\n",
        "    Google Drive íŒŒì¼ ìŠ¤ìº”\n",
        "    \n",
        "    Args:\n",
        "        service: Google Drive API ì„œë¹„ìŠ¤\n",
        "        folder_id: ìŠ¤ìº”í•  í´ë” ID (ê¸°ë³¸ê°’: 'root')\n",
        "        folder_name: í´ë” ì´ë¦„ (í‘œì‹œìš©)\n",
        "    \n",
        "    Returns:\n",
        "        list: íŒŒì¼ ì •ë³´ ë¦¬ìŠ¤íŠ¸\n",
        "    \"\"\"\n",
        "    files = []\n",
        "    \n",
        "    try:\n",
        "        # í´ë” ë‚´ íŒŒì¼ ëª©ë¡ ì¡°íšŒ\n",
        "        query = f\"'{folder_id}' in parents and trashed=false\"\n",
        "        \n",
        "        results = service.files().list(\n",
        "            q=query,\n",
        "            pageSize=1000,\n",
        "            fields=\"nextPageToken, files(id, name, mimeType, size, createdTime, modifiedTime, parents, shared)\"\n",
        "        ).execute()\n",
        "        \n",
        "        items = results.get('files', [])\n",
        "        \n",
        "        for item in items:\n",
        "            file_info = {\n",
        "                'id': item['id'],\n",
        "                'name': item['name'],\n",
        "                'mimeType': item.get('mimeType', ''),\n",
        "                'size': int(item.get('size', 0)) if item.get('size') else 0,\n",
        "                'createdTime': item.get('createdTime', ''),\n",
        "                'modifiedTime': item.get('modifiedTime', ''),\n",
        "                'parents': item.get('parents', []),\n",
        "                'shared': item.get('shared', False),\n",
        "                'isFolder': item.get('mimeType') == 'application/vnd.google-apps.folder'\n",
        "            }\n",
        "            files.append(file_info)\n",
        "        \n",
        "        print(f\"ğŸ“ {folder_name} í´ë”ì—ì„œ {len(files)}ê°œ í•­ëª©ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
        "        \n",
        "    except HttpError as error:\n",
        "        print(f\"âŒ íŒŒì¼ ìŠ¤ìº” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error}\")\n",
        "    \n",
        "    return files\n",
        "\n",
        "def format_file_size(size_bytes):\n",
        "    \"\"\"íŒŒì¼ í¬ê¸° í¬ë§·íŒ…\"\"\"\n",
        "    if size_bytes == 0:\n",
        "        return \"0B\"\n",
        "    \n",
        "    size_names = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]\n",
        "    i = 0\n",
        "    while size_bytes >= 1024 and i < len(size_names) - 1:\n",
        "        size_bytes /= 1024.0\n",
        "        i += 1\n",
        "    \n",
        "    return f\"{size_bytes:.1f}{size_names[i]}\"\n",
        "\n",
        "print(\"âœ… íŒŒì¼ ìŠ¤ìº” í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê°œì¸ ê³„ì • íŒŒì¼ ìŠ¤ìº”\n",
        "print(\"ğŸ” ê°œì¸ ê³„ì • íŒŒì¼ì„ ìŠ¤ìº”í•©ë‹ˆë‹¤...\")\n",
        "personal_files = scan_drive_files(personal_service, 'root', 'ê°œì¸ ê³„ì •')\n",
        "\n",
        "# íŒŒì¼ ì •ë³´ ìš”ì•½\n",
        "if personal_files:\n",
        "    df_personal = pd.DataFrame(personal_files)\n",
        "    \n",
        "    print(f\"\\nğŸ“Š ê°œì¸ ê³„ì • íŒŒì¼ ìš”ì•½:\")\n",
        "    print(f\"  - ì´ íŒŒì¼ ìˆ˜: {len(df_personal)}\")\n",
        "    print(f\"  - í´ë” ìˆ˜: {df_personal['isFolder'].sum()}\")\n",
        "    print(f\"  - íŒŒì¼ ìˆ˜: {(~df_personal['isFolder']).sum()}\")\n",
        "    \n",
        "    if not df_personal['isFolder'].all():\n",
        "        total_size = df_personal[~df_personal['isFolder']]['size'].sum()\n",
        "        print(f\"  - ì´ í¬ê¸°: {format_file_size(total_size)}\")\n",
        "    \n",
        "    # íŒŒì¼ íƒ€ì…ë³„ ë¶„í¬\n",
        "    print(f\"\\nğŸ“‹ íŒŒì¼ íƒ€ì…ë³„ ë¶„í¬:\")\n",
        "    mime_counts = df_personal['mimeType'].value_counts().head(10)\n",
        "    for mime_type, count in mime_counts.items():\n",
        "        print(f\"  {mime_type}: {count}ê°œ\")\n",
        "    \n",
        "    # ê³µìœ  íŒŒì¼ ìˆ˜\n",
        "    shared_count = df_personal['shared'].sum()\n",
        "    print(f\"\\nğŸ”— ê³µìœ  ì¤‘ì¸ íŒŒì¼: {shared_count}ê°œ\")\n",
        "    \n",
        "    # ëŒ€ìš©ëŸ‰ íŒŒì¼ í™•ì¸\n",
        "    large_files = df_personal[df_personal['size'] > 100 * 1024 * 1024]  # 100MB ì´ìƒ\n",
        "    if not large_files.empty:\n",
        "        print(f\"\\nğŸ“¦ ëŒ€ìš©ëŸ‰ íŒŒì¼ (100MB ì´ìƒ): {len(large_files)}ê°œ\")\n",
        "        for _, file in large_files.iterrows():\n",
        "            print(f\"  - {file['name']}: {format_file_size(file['size'])}\")\n",
        "else:\n",
        "    print(\"âŒ ê°œì¸ ê³„ì •ì—ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def migrate_file(source_service, target_service, file_info, target_folder_id='root'):\n",
        "    \"\"\"\n",
        "    ë‹¨ì¼ íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜\n",
        "    \n",
        "    Args:\n",
        "        source_service: ì†ŒìŠ¤ Google Drive API ì„œë¹„ìŠ¤\n",
        "        target_service: íƒ€ê²Ÿ Google Drive API ì„œë¹„ìŠ¤\n",
        "        file_info: íŒŒì¼ ì •ë³´ ë”•ì…”ë„ˆë¦¬\n",
        "        target_folder_id: íƒ€ê²Ÿ í´ë” ID\n",
        "    \n",
        "    Returns:\n",
        "        dict: ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼\n",
        "    \"\"\"\n",
        "    result = {\n",
        "        'file_id': file_info['id'],\n",
        "        'file_name': file_info['name'],\n",
        "        'success': False,\n",
        "        'error': None,\n",
        "        'new_file_id': None\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        if file_info['isFolder']:\n",
        "            # í´ë” ìƒì„±\n",
        "            folder_metadata = {\n",
        "                'name': file_info['name'],\n",
        "                'mimeType': 'application/vnd.google-apps.folder',\n",
        "                'parents': [target_folder_id]\n",
        "            }\n",
        "            \n",
        "            new_folder = target_service.files().create(\n",
        "                body=folder_metadata,\n",
        "                fields='id'\n",
        "            ).execute()\n",
        "            \n",
        "            result['success'] = True\n",
        "            result['new_file_id'] = new_folder.get('id')\n",
        "            \n",
        "        else:\n",
        "            # íŒŒì¼ ë³µì‚¬ (Google Drive API v3ì˜ ì˜¬ë°”ë¥¸ ë°©ë²•)\n",
        "            file_metadata = {\n",
        "                'name': file_info['name'],\n",
        "                'parents': [target_folder_id]\n",
        "            }\n",
        "            \n",
        "            # files().copy() ë©”ì„œë“œ ì‚¬ìš©\n",
        "            new_file = target_service.files().copy(\n",
        "                fileId=file_info['id'],\n",
        "                body=file_metadata,\n",
        "                fields='id'\n",
        "            ).execute()\n",
        "            \n",
        "            result['success'] = True\n",
        "            result['new_file_id'] = new_file.get('id')\n",
        "    \n",
        "    except HttpError as error:\n",
        "        result['error'] = str(error)\n",
        "    except Exception as error:\n",
        "        result['error'] = str(error)\n",
        "    \n",
        "    return result\n",
        "\n",
        "def migrate_files_batch(source_service, target_service, files_df, target_folder_id='root'):\n",
        "    \"\"\"\n",
        "    íŒŒì¼ ë°°ì¹˜ ë§ˆì´ê·¸ë ˆì´ì…˜\n",
        "    \n",
        "    Args:\n",
        "        source_service: ì†ŒìŠ¤ Google Drive API ì„œë¹„ìŠ¤\n",
        "        target_service: íƒ€ê²Ÿ Google Drive API ì„œë¹„ìŠ¤\n",
        "        files_df: íŒŒì¼ ì •ë³´ DataFrame\n",
        "        target_folder_id: íƒ€ê²Ÿ í´ë” ID\n",
        "    \n",
        "    Returns:\n",
        "        list: ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    \n",
        "    print(f\"ğŸš€ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì´ {len(files_df)}ê°œ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\")\n",
        "    \n",
        "    # ì§„í–‰ë¥  í‘œì‹œë¥¼ ìœ„í•œ tqdm ì„¤ì •\n",
        "    for idx, (_, file_info) in enumerate(tqdm(files_df.iterrows(), total=len(files_df), desc=\"ë§ˆì´ê·¸ë ˆì´ì…˜ ì§„í–‰\")):\n",
        "        result = migrate_file(source_service, target_service, file_info, target_folder_id)\n",
        "        results.append(result)\n",
        "        \n",
        "        # ì§„í–‰ ìƒí™© ì¶œë ¥\n",
        "        if result['success']:\n",
        "            print(f\"âœ… {file_info['name']} - ì„±ê³µ\")\n",
        "        else:\n",
        "            print(f\"âŒ {file_info['name']} - ì‹¤íŒ¨: {result['error']}\")\n",
        "        \n",
        "        # API í• ë‹¹ëŸ‰ ê´€ë¦¬ë¥¼ ìœ„í•œ ì ì‹œ ëŒ€ê¸°\n",
        "        if (idx + 1) % 10 == 0:\n",
        "            import time\n",
        "            time.sleep(1)\n",
        "    \n",
        "    return results\n",
        "\n",
        "print(\"âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë§ˆì´ê·¸ë ˆì´ì…˜ ì„¤ì • ë° ì‹¤í–‰\n",
        "print(\"âš™ï¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ì„¤ì •ì„ í™•ì¸í•©ë‹ˆë‹¤.\")\n",
        "print(f\"  - ìµœëŒ€ íŒŒì¼ í¬ê¸°: {format_file_size(MAX_FILE_SIZE)}\")\n",
        "print(f\"  - ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}\")\n",
        "print(f\"  - ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜: {MAX_RETRIES}\")\n",
        "\n",
        "# ë§ˆì´ê·¸ë ˆì´ì…˜í•  íŒŒì¼ í•„í„°ë§\n",
        "if personal_files:\n",
        "    df_personal = pd.DataFrame(personal_files)\n",
        "    \n",
        "    # ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ëŠ¥í•œ íŒŒì¼ í•„í„°ë§\n",
        "    migratable_files = df_personal[\n",
        "        (df_personal['size'] <= MAX_FILE_SIZE) | \n",
        "        (df_personal['isFolder'] == True)\n",
        "    ]\n",
        "    \n",
        "    print(f\"\\nâœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ëŠ¥í•œ íŒŒì¼: {len(migratable_files)}ê°œ\")\n",
        "    \n",
        "    # ë§ˆì´ê·¸ë ˆì´ì…˜ ë¶ˆê°€ëŠ¥í•œ íŒŒì¼ í™•ì¸\n",
        "    too_large_files = df_personal[\n",
        "        (df_personal['size'] > MAX_FILE_SIZE) & \n",
        "        (df_personal['isFolder'] == False)\n",
        "    ]\n",
        "    \n",
        "    if not too_large_files.empty:\n",
        "        print(f\"\\nâš ï¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ë¶ˆê°€ëŠ¥í•œ íŒŒì¼ (í¬ê¸° ì´ˆê³¼): {len(too_large_files)}ê°œ\")\n",
        "        for _, file in too_large_files.iterrows():\n",
        "            print(f\"  - {file['name']}: {format_file_size(file['size'])}\")\n",
        "else:\n",
        "    print(\"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    migratable_files = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ (ì£¼ì˜: ì‹¤ì œ ì‹¤í–‰í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ)\n",
        "print(\"âš ï¸ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?\")\n",
        "print(\"ì£¼ì˜: ì´ ì‘ì—…ì€ ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
        "print(\"\\nì‹¤í–‰í•˜ë ¤ë©´ ì•„ë˜ ì…€ì˜ ì£¼ì„ì„ í•´ì œí•˜ê³  ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
        "\n",
        "# ì‹¤í–‰í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”\n",
        "# if not migratable_files.empty:\n",
        "#     print(\"ğŸš€ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "#     results = migrate_files_batch(personal_service, work_service, migratable_files)\n",
        "#     \n",
        "#     # ê²°ê³¼ ìš”ì•½\n",
        "#     success_count = sum(1 for r in results if r['success'])\n",
        "#     fail_count = len(results) - success_count\n",
        "#     \n",
        "#     print(f\"\\nğŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!\")\n",
        "#     print(f\"  - ì„±ê³µ: {success_count}ê°œ\")\n",
        "#     print(f\"  - ì‹¤íŒ¨: {fail_count}ê°œ\")\n",
        "#     \n",
        "#     # ì‹¤íŒ¨í•œ íŒŒì¼ ëª©ë¡\n",
        "#     if fail_count > 0:\n",
        "#         print(\"\\nâŒ ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:\")\n",
        "#         for result in results:\n",
        "#             if not result['success']:\n",
        "#                 print(f\"  - {result['file_name']}: {result['error']}\")\n",
        "# else:\n",
        "#     print(\"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# íšŒì‚¬ ê³„ì • íŒŒì¼ í™•ì¸\n",
        "print(\"ğŸ” íšŒì‚¬ ê³„ì • íŒŒì¼ì„ í™•ì¸í•©ë‹ˆë‹¤...\")\n",
        "work_files = scan_drive_files(work_service, 'root', 'íšŒì‚¬ ê³„ì •')\n",
        "\n",
        "if work_files:\n",
        "    df_work = pd.DataFrame(work_files)\n",
        "    \n",
        "    print(f\"\\nğŸ“Š íšŒì‚¬ ê³„ì • íŒŒì¼ ìš”ì•½:\")\n",
        "    print(f\"  - ì´ íŒŒì¼ ìˆ˜: {len(df_work)}\")\n",
        "    print(f\"  - í´ë” ìˆ˜: {df_work['isFolder'].sum()}\")\n",
        "    print(f\"  - íŒŒì¼ ìˆ˜: {(~df_work['isFolder']).sum()}\")\n",
        "    \n",
        "    if not df_work['isFolder'].all():\n",
        "        total_size = df_work[~df_work['isFolder']]['size'].sum()\n",
        "        print(f\"  - ì´ í¬ê¸°: {format_file_size(total_size)}\")\n",
        "    \n",
        "    # ìµœê·¼ ìƒì„±ëœ íŒŒì¼ í™•ì¸\n",
        "    recent_files = df_work.head(10)\n",
        "    print(f\"\\nğŸ“‹ ìµœê·¼ íŒŒì¼ë“¤:\")\n",
        "    for _, file in recent_files.iterrows():\n",
        "        print(f\"  - {file['name']} ({file['mimeType']})\")\n",
        "else:\n",
        "    print(\"âŒ íšŒì‚¬ ê³„ì •ì—ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!\n",
        "\n",
        "### ë‹¤ìŒ ë‹¨ê³„:\n",
        "1. **íšŒì‚¬ ê³„ì •ì—ì„œ íŒŒì¼ë“¤ì´ ì˜¬ë°”ë¥´ê²Œ ë³µì‚¬ë˜ì—ˆëŠ”ì§€ í™•ì¸**\n",
        "2. **ê³µìœ  ì„¤ì •ì´ í•„ìš”í•œ íŒŒì¼ë“¤ì— ëŒ€í•´ ê¶Œí•œ ì¬ì„¤ì •**\n",
        "3. **ê°œì¸ ê³„ì •ì˜ íŒŒì¼ë“¤ì„ ì •ë¦¬ (í•„ìš”ì‹œ)**\n",
        "4. **íŒ€ì›ë“¤ê³¼ ê³µìœ  í´ë” ì„¤ì •**\n",
        "\n",
        "### ì£¼ì˜ì‚¬í•­:\n",
        "- **ê°œì¸ ê³„ì •ì˜ íŒŒì¼ì„ ì‚­ì œí•˜ê¸° ì „ì— ì¶©ë¶„íˆ í™•ì¸í•˜ì„¸ìš”**\n",
        "- **ì¤‘ìš”í•œ íŒŒì¼ì€ ë°±ì—…ì„ ë§Œë“¤ì–´ë‘ì„¸ìš”**\n",
        "- **ê³µìœ  ê¶Œí•œì´ í•„ìš”í•œ íŒŒì¼ë“¤ì€ ìˆ˜ë™ìœ¼ë¡œ ì¬ì„¤ì •í•˜ì„¸ìš”**\n",
        "\n",
        "### ë¬¸ì œê°€ ë°œìƒí–ˆë‹¤ë©´:\n",
        "- ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”\n",
        "- ì‹¤íŒ¨í•œ íŒŒì¼ë“¤ì„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”\n",
        "- ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
